{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (412000, 20), test size: (264000, 20)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"./pan19_df_clean_train_full_features.pkl\")\n",
    "df_test = pd.read_pickle(\"./pan19_df_clean_test_full_features.pkl\")\n",
    "\n",
    "# PAZI NA OVO, zakomentirati prije pravog pokretanja\n",
    "#num_examples = 20_000\n",
    "#df_train = df_train.loc[list(range(5*num_examples)), :]\n",
    "#df_test = df_test.loc[list(range(num_examples)), :]\n",
    "\n",
    "print(f\"train size: {df_train.shape}, test size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = [\"word_count\", \"char_count\", \"word_density\", \"total_length\", \"capitals\", \"caps_vs_length\"]\n",
    "punctuation_features = [\"num_exclamation_marks\", \"num_question_marks\", \"num_punctuation\", \"num_symbols\"]\n",
    "uniques_features = [\"num_unique_words\", \"words_vs_unique\", \"word_unique_percent\"]\n",
    "means_features = [\"num_retweet\", \"num_url\", \"num_number\"]\n",
    "\n",
    "all_new_features = word_features + punctuation_features + uniques_features + means_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['bot', 'human']\n",
      "\n",
      "train label dimensions: (100000, 1)\n",
      "test label dimensions: (20000, 1)\n",
      "train dimensions: (100000, 220)\n",
      "test dimensions: (20000, 24)\n"
     ]
    }
   ],
   "source": [
    "multilabel_binarizer = LabelBinarizer()\n",
    "multilabel_binarizer.fit(df_train['bot'])\n",
    "print(f\"labels: {list(multilabel_binarizer.classes_)}\")\n",
    "print()\n",
    "\n",
    "ytrain = multilabel_binarizer.transform(df_train['bot'])\n",
    "ytest = multilabel_binarizer.transform(df_test['bot'])\n",
    "print(f\"train label dimensions: {len(ytrain), len(ytrain[0])}\")\n",
    "print(f\"test label dimensions: {len(ytest), len(ytest[0])}\")\n",
    "\n",
    "xtrain=df_train.clean_tweet\n",
    "xtest=df_test.clean_tweet\n",
    "print(f\"train dimensions: {len(xtrain), len(xtrain[0])}\")\n",
    "print(f\"test dimensions: {len(xtest), len(xtest[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Koeficijenti:\n",
    "tfidf_max_df = 0.8\n",
    "tfidf_max_features = 10000\n",
    "tfidf_ngram_range = (1,3)\n",
    "\n",
    "k_features = 500    # ANOVA feature count\n",
    "clf_random = 31337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (100000, 10000)\n",
      "test shape: (20000, 10000)\n",
      "\n",
      "(100000, 10000)\n",
      "(100000, 20)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'numpy.ndarray'>\n",
      "(100000, 20)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_df=tfidf_max_df, max_features=tfidf_max_features, ngram_range = tfidf_ngram_range)\n",
    "\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xtest_tfidf = tfidf_vectorizer.transform(xtest)\n",
    "print (f\"train shape: {xtrain_tfidf.shape}\\ntest shape: {xtest_tfidf.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = xtrain_tfidf, xtest_tfidf, ytrain, ytest\n",
    "\n",
    "print()\n",
    "print(X_train.shape)\n",
    "X_train_new = SelectKBest(chi2, k=20).fit_transform(X_train, y_train)\n",
    "print(X_train_new.shape)\n",
    "print(type(X_train_new))\n",
    "print(type(X_train_new.toarray()))\n",
    "print(X_train_new.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76     10000\n",
      "           1       0.77      0.74      0.76     10000\n",
      "\n",
      "    accuracy                           0.76     20000\n",
      "   macro avg       0.76      0.76      0.76     20000\n",
      "weighted avg       0.76      0.76      0.76     20000\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "## Klasifikacija bez hand-crafted featurea\n",
    "\n",
    "from sklearn import svm\n",
    "# from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "X_train, X_test, y_train, y_test = xtrain_tfidf, xtest_tfidf, ytrain, ytest\n",
    "\n",
    "# ANOVA SVM-C\n",
    "# 1) anova filter, take 3 best ranked features\n",
    "# 2) svm\n",
    "\n",
    "anova_filter = SelectKBest(f_regression, k=k_features)\n",
    "clf = svm.LinearSVC(max_iter=5000, dual=False, random_state=clf_random)\n",
    "\n",
    "anova_svm = make_pipeline(anova_filter, clf)\n",
    "anova_svm.fit(X_train.toarray(), y_train.ravel())\n",
    "\n",
    "\n",
    "y_pred = anova_svm.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "coef = anova_svm[:-1].inverse_transform(anova_svm['linearsvc'].coef_)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.76\n",
      "f1-macro: 0.7599362174536153\n"
     ]
    }
   ],
   "source": [
    "# no mentions, hashtags, urls, numbers\n",
    "print(f\"accuracy_score: {accuracy_score(ytest, y_pred)}\")\n",
    "print(f\"f1-macro: {f1_score(ytest, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (100000, 10016)\n",
      "test shape: (20000, 10016)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 231)\t0.1070060091441348\n",
      "  (0, 244)\t0.1329811514246474\n",
      "  (0, 492)\t0.14275085349911712\n",
      "  (0, 965)\t0.0946049494358762\n",
      "  (0, 984)\t0.15361995118469748\n",
      "  (0, 985)\t0.16269323971366992\n",
      "  (0, 1312)\t0.16642715988597387\n",
      "  (0, 1822)\t0.10859843992917596\n",
      "  (0, 1829)\t0.1396898145391235\n",
      "  (0, 1830)\t0.1403264374150171\n",
      "  (0, 1952)\t0.09513522262420086\n",
      "  (0, 2387)\t0.12139924566861027\n",
      "  (0, 2388)\t0.1457718014524301\n",
      "  (0, 2389)\t0.14713823460049275\n",
      "  (0, 2621)\t0.10014302858402735\n",
      "  (0, 2631)\t0.1457718014524301\n",
      "  (0, 2632)\t0.1457718014524301\n",
      "  (0, 2637)\t0.13001022806493032\n",
      "  (0, 2638)\t0.16269323971366992\n",
      "  (0, 3030)\t0.09858266331338617\n",
      "  (0, 3036)\t0.11112700913670026\n",
      "  (0, 3038)\t0.14533846197443526\n",
      "  (0, 4015)\t0.16146262086256608\n",
      "  (0, 4024)\t0.10212074040138394\n",
      "  (0, 4064)\t0.1369401189789827\n",
      "  :\t:\n",
      "  (0, 8753)\t0.13762395491559562\n",
      "  (0, 8910)\t0.13153348473043952\n",
      "  (0, 9028)\t0.078053783936493\n",
      "  (0, 9039)\t0.14533846197443526\n",
      "  (0, 9308)\t0.2231596706367789\n",
      "  (0, 9313)\t0.13386391604858608\n",
      "  (0, 9314)\t0.13443849266214233\n",
      "  (0, 9385)\t0.05988655469599187\n",
      "  (0, 9445)\t0.05721890547438021\n",
      "  (0, 10000)\t1.8243927949962824\n",
      "  (0, 10001)\t2.8502085885685036\n",
      "  (0, 10002)\t-0.7602475717292816\n",
      "  (0, 10003)\t2.7336552352957275\n",
      "  (0, 10004)\t2.742486998742623\n",
      "  (0, 10005)\t0.4629123792993709\n",
      "  (0, 10006)\t-0.2938302311419863\n",
      "  (0, 10007)\t-0.24844097543211907\n",
      "  (0, 10008)\t3.270997057450695\n",
      "  (0, 10009)\t-0.1135036581472016\n",
      "  (0, 10010)\t1.9899118638600026\n",
      "  (0, 10011)\t-0.260525895314608\n",
      "  (0, 10012)\t-0.2605258953146066\n",
      "  (0, 10013)\t0.9204122617378736\n",
      "  (0, 10014)\t1.857047962584358\n",
      "  (0, 10015)\t1.859102004113765\n",
      "(1, 10016)\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "\n",
    "#print(xtrain_tfidf.todense().shape)\n",
    "#print(df_train_full[all_new_features].values.shape)\n",
    "#print(xtrain_tfidf.todense())\n",
    "#print(df_train_full[all_new_features].values)\n",
    "#xtrain_dense = xtrain_tfidf.todense()\n",
    "#xtest_dense = xtest_tfidf.todense()\n",
    "\n",
    "X_train_full = sp.sparse.hstack((xtrain_tfidf, sp.sparse.csr_matrix(df_train[all_new_features].values)), \"csr\")\n",
    "X_test_full = sp.sparse.hstack((xtest_tfidf, sp.sparse.csr_matrix(df_test[all_new_features].values)), \"csr\")\n",
    "print (f\"train shape: {X_train_full.shape}\\ntest shape: {X_test_full.shape}\")\n",
    "print(type(X_train_full))\n",
    "print(X_train_full[1])\n",
    "print(X_train_full[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77     10000\n",
      "           1       0.77      0.76      0.77     10000\n",
      "\n",
      "    accuracy                           0.77     20000\n",
      "   macro avg       0.77      0.77      0.77     20000\n",
      "weighted avg       0.77      0.77      0.77     20000\n",
      "\n",
      "accuracy_score: 0.76985\n",
      "f1-macro: 0.7698436563157771\n"
     ]
    }
   ],
   "source": [
    "anova_filter = SelectKBest(f_regression, k=k_features)\n",
    "clf = svm.LinearSVC(max_iter=5000, dual=False, random_state=clf_random)\n",
    "\n",
    "anova_svm = make_pipeline(anova_filter, clf)\n",
    "anova_svm.fit(X_train_full, y_train.ravel())\n",
    "\n",
    "y_pred = anova_svm.predict(X_test_full)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"accuracy_score: {accuracy_score(ytest, y_pred)}\")\n",
    "print(f\"f1-macro: {f1_score(ytest, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
